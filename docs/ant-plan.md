# Progressive Disclosure Architecture Implementation Plan

## Executive Summary

Implementation plan for claude-indexer v2.4 enhancing semantic search capabilities through AST-based content chunking while maintaining stable v2.3 foundation. This approach provides 90% faster overview queries and precise implementation search when needed.

**Key Metrics:**
- ðŸŽ¯ Zero breaking changes to v2.3 system
- âš¡ 90% faster responses for overview queries
- ðŸ“Š 20-35% improved semantic search accuracy
- ðŸ’° Cost controlled - implementation processing only on demand

## Architecture Overview

### Current v2.3 System (Preserved)
```
Pipeline 1: Tree-sitter + Jedi â†’ Metadata Chunks
- Content: Entity names, signatures, docstrings
- Size: 50-200 characters per chunk
- Focus: "What exists and how it connects"
```

### Enhanced v2.4 System (Addition)
```
Pipeline 1: Tree-sitter + Jedi â†’ Metadata Chunks (unchanged)
Pipeline 2: AST + Jedi â†’ Implementation Chunks (new)
- Content: Full source code with semantic metadata
- Size: 100-500+ lines per chunk
- Focus: "What the code actually does"
```

## Phase 1: Dual Vector Storage Implementation

### 1.1 Schema Extension

**Entity Schema Update:**
```python
# claude_indexer/models/entity.py
from typing import Literal, Optional, Dict, Any

ChunkType = Literal["metadata", "implementation"]

class EntityChunk:
    """Represents a chunk of entity content for vector storage"""
    id: str  # Format: "{file_id}::{entity_name}::{chunk_type}"
    entity_name: str
    chunk_type: ChunkType
    content: str
    metadata: Dict[str, Any]
    
    def to_vector_payload(self) -> Dict[str, Any]:
        """Convert to Qdrant payload format"""
        return {
            "name": self.entity_name,
            "chunk_type": self.chunk_type,
            "content": self.content,
            **self.metadata
        }
```

### 1.2 AST + Jedi Content Extraction

**Implementation Pipeline:**
```python
# claude_indexer/processors/ast_extractor.py
import ast
import jedi
from pathlib import Path
from typing import List, Optional

class ASTContentExtractor:
    """Extract full implementation content using AST + Jedi"""
    
    def __init__(self):
        self.jedi_project = jedi.Project(path=".")
    
    def extract_implementation(self, file_path: Path) -> List[EntityChunk]:
        """Extract implementation chunks with semantic metadata"""
        chunks = []
        
        with open(file_path) as f:
            source_code = f.read()
        
        # Parse AST
        tree = ast.parse(source_code, filename=str(file_path))
        
        # Create Jedi script for semantic analysis
        script = jedi.Script(source_code, path=file_path, project=self.jedi_project)
        
        # Extract function implementations
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                chunk = self._extract_function_chunk(node, source_code, script)
                if chunk:
                    chunks.append(chunk)
            elif isinstance(node, ast.ClassDef):
                chunk = self._extract_class_chunk(node, source_code, script)
                if chunk:
                    chunks.append(chunk)
        
        return chunks
    
    def _extract_function_chunk(self, node: ast.FunctionDef, 
                               source: str, script: jedi.Script) -> Optional[EntityChunk]:
        """Extract function implementation with semantic metadata"""
        # Get source code
        start_line = node.lineno - 1
        end_line = node.end_lineno
        lines = source.split('\n')[start_line:end_line]
        implementation = '\n'.join(lines)
        
        # Get Jedi semantic data
        try:
            definition = script.goto(node.lineno, node.col_offset)[0]
            
            # Extract semantic metadata
            semantic_metadata = {
                "inferred_types": self._get_type_hints(definition),
                "calls": self._extract_function_calls(node),
                "imports_used": self._extract_imports_used(node, script),
                "exceptions_handled": self._extract_exceptions(node),
                "complexity": self._calculate_complexity(node)
            }
        except:
            semantic_metadata = {}
        
        return EntityChunk(
            id=f"{hash(source)}::{node.name}::implementation",
            entity_name=node.name,
            chunk_type="implementation",
            content=implementation,
            metadata={
                "file_path": str(script.path),
                "start_line": node.lineno,
                "end_line": node.end_lineno,
                "semantic_metadata": semantic_metadata
            }
        )
```

### 1.3 Storage Integration

**Qdrant Storage Update:**
```python
# claude_indexer/storage/qdrant.py
class QdrantStore:
    def store_dual_chunks(self, metadata_chunk: EntityChunk, 
                         implementation_chunk: Optional[EntityChunk]):
        """Store both metadata and implementation chunks"""
        
        # Store metadata chunk (existing flow)
        metadata_vector = self._embed_content(metadata_chunk.content)
        self.client.upsert(
            collection_name=self.collection_name,
            points=[
                PointStruct(
                    id=metadata_chunk.id,
                    vector=metadata_vector,
                    payload={
                        **metadata_chunk.to_vector_payload(),
                        "has_implementation": implementation_chunk is not None
                    }
                )
            ]
        )
        
        # Store implementation chunk if available
        if implementation_chunk:
            impl_vector = self._embed_content(implementation_chunk.content)
            self.client.upsert(
                collection_name=self.collection_name,
                points=[
                    PointStruct(
                        id=implementation_chunk.id,
                        vector=impl_vector,
                        payload=implementation_chunk.to_vector_payload()
                    )
                ]
            )
```

## Phase 2: Enhanced MCP Server

### 2.1 MCP Tool Enhancement

**Enhanced search_similar:**
```javascript
// mcp-qdrant-memory/src/tools/search.ts
export async function searchSimilar(
  query: string, 
  limit: number = 10
): Promise<SearchResult[]> {
  // Search metadata chunks only for performance
  const results = await qdrantClient.search(collection, {
    vector: await embedQuery(query),
    filter: {
      must: [{ key: "chunk_type", match: { value: "metadata" } }]
    },
    limit
  });
  
  // Enhance results with implementation hints
  return results.map(result => ({
    type: result.payload.type,
    score: result.score,
    data: {
      name: result.payload.name,
      ...result.payload,
      has_implementation: result.payload.has_implementation || false
    }
  }));
}
```

**New get_implementation tool:**
```javascript
// mcp-qdrant-memory/src/tools/implementation.ts
export async function getImplementation(
  entityName: string
): Promise<ImplementationResult | null> {
  const results = await qdrantClient.search(collection, {
    filter: {
      must: [
        { key: "chunk_type", match: { value: "implementation" } },
        { key: "name", match: { value: entityName } }
      ]
    },
    limit: 1
  });
  
  if (results.length === 0) {
    return null;
  }
  
  const result = results[0];
  return {
    entity_name: entityName,
    source_code: result.payload.content,
    semantic_metadata: result.payload.semantic_metadata,
    file_path: result.payload.file_path,
    lines: {
      start: result.payload.start_line,
      end: result.payload.end_line
    }
  };
}
```

### 2.2 Tool Registration

**MCP Server Update:**
```javascript
// mcp-qdrant-memory/src/index.ts
server.setRequestHandler(ListToolsRequestSchema, async () => ({
  tools: [
    // Existing tools...
    {
      name: "search_similar",
      description: "Search for similar entities with implementation hints",
      inputSchema: {
        type: "object",
        properties: {
          query: { type: "string" },
          limit: { type: "number", default: 10 }
        },
        required: ["query"]
      }
    },
    // New tool
    {
      name: "get_implementation", 
      description: "Get full implementation code for an entity",
      inputSchema: {
        type: "object",
        properties: {
          entity_name: { type: "string" }
        },
        required: ["entity_name"]
      }
    }
  ]
}));
```

## Testing Strategy

### 3.1 Unit Tests

**Dual Chunk Storage Test:**
```python
# tests/unit/test_dual_chunking.py
def test_dual_chunk_storage():
    """Test storing metadata and implementation chunks"""
    extractor = ASTContentExtractor()
    store = QdrantStore("test_collection")
    
    # Create test file
    test_code = '''
def calculate_sum(a: int, b: int) -> int:
    """Add two numbers together."""
    result = a + b
    return result
'''
    
    # Extract chunks
    metadata_chunk = EntityChunk(
        id="file1::calculate_sum::metadata",
        entity_name="calculate_sum",
        chunk_type="metadata",
        content="function: calculate_sum | Signature: (a: int, b: int) -> int | Add two numbers",
        metadata={"type": "function"}
    )
    
    impl_chunks = extractor.extract_implementation(test_code)
    
    # Store dual chunks
    store.store_dual_chunks(metadata_chunk, impl_chunks[0])
    
    # Verify storage
    search_results = store.search("calculate sum", filter={"chunk_type": "metadata"})
    assert search_results[0]["has_implementation"] is True
```

### 3.2 Integration Tests

**MCP Progressive Disclosure Test:**
```javascript
// tests/integration/test_progressive_disclosure.js
test('Progressive disclosure workflow', async () => {
  // Step 1: Search returns metadata with hints
  const searchResults = await mcp.callTool('search_similar', {
    query: 'authentication function'
  });
  
  expect(searchResults[0].data.has_implementation).toBe(true);
  expect(searchResults[0].data.name).toBe('authenticate_user');
  
  // Step 2: Get implementation on demand
  const implementation = await mcp.callTool('get_implementation', {
    entity_name: 'authenticate_user'
  });
  
  expect(implementation.source_code).toContain('def authenticate_user');
  expect(implementation.semantic_metadata.calls).toContain('verify_password');
});
```

## Debug Tips

### 4.1 Common Issues

**Issue: Implementation chunks not created**
```python
# Debug: Add verbose logging
import logging
logging.basicConfig(level=logging.DEBUG)

class ASTContentExtractor:
    def extract_implementation(self, file_path):
        logger.debug(f"Processing file: {file_path}")
        # ... extraction logic
        logger.debug(f"Extracted {len(chunks)} implementation chunks")
```

**Issue: MCP tool not discovering new function**
```javascript
// Debug: Check tool registration
server.setRequestHandler(ListToolsRequestSchema, async () => {
  console.log("Available tools:", tools.map(t => t.name));
  return { tools };
});
```

### 4.2 Performance Monitoring

**Chunk Size Analysis:**
```python
# utils/analyze_chunk_sizes.py
def analyze_chunk_distribution(collection_name: str):
    """Analyze chunk type and size distribution"""
    store = QdrantStore(collection_name)
    
    # Get all chunks
    metadata_chunks = store.client.scroll(
        collection_name=collection_name,
        scroll_filter=Filter(must=[FieldCondition(key="chunk_type", match=MatchValue(value="metadata"))]),
        limit=10000
    )
    
    impl_chunks = store.client.scroll(
        collection_name=collection_name,
        scroll_filter=Filter(must=[FieldCondition(key="chunk_type", match=MatchValue(value="implementation"))]),
        limit=10000
    )
    
    print(f"Metadata chunks: {len(metadata_chunks[0])}")
    print(f"Implementation chunks: {len(impl_chunks[0])}")
    print(f"Ratio: {len(impl_chunks[0]) / len(metadata_chunks[0]):.2%}")
```

## Rollout Plan

### Week 1-2: Core Infrastructure
- [ ] Implement EntityChunk model
- [ ] Build AST + Jedi extraction pipeline
- [ ] Update Qdrant storage for dual chunks
- [ ] Add comprehensive unit tests

### Week 3: MCP Enhancement
- [ ] Update search_similar with hints
- [ ] Implement get_implementation tool
- [ ] Update tool registration
- [ ] Integration testing

### Week 4: Testing & Validation
- [ ] Performance benchmarking
- [ ] Real-world usage testing
- [ ] Documentation updates
- [ ] Production deployment

## Success Metrics

### Technical Metrics
- âœ… Maintain 158/158 test pass rate
- âœ… Preserve 15x incremental performance
- âœ… Zero breaking changes to v2.3 API

### Quality Metrics
- âœ… 20-35% improved semantic search for implementation queries
- âœ… 90% faster metadata-only queries
- âœ… <2s response time for implementation retrieval

### User Experience
- âœ… Natural progressive disclosure flow
- âœ… Clear implementation availability hints
- âœ… No information overload in search results

## Migration Guide

### For Existing v2.3 Users
```bash
# No action required - fully backward compatible
# New features available automatically after upgrade

# Optional: Re-index for implementation chunks
claude-indexer -p /project -c project-name --full-reindex
```

### For MCP Users
```javascript
// Existing searches continue to work
const results = await search_similar("auth function");

// New capability available automatically
if (results[0].data.has_implementation) {
  const impl = await get_implementation(results[0].data.name);
}
```

## Conclusion

This implementation plan provides a clear path to enhanced semantic search capabilities while maintaining the stability and performance of the v2.3 system. The progressive disclosure architecture ensures optimal performance for all query types while providing deep implementation understanding when needed.