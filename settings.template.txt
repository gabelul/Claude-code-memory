# Claude Code Memory Solution - Configuration Settings Template
# Copy this file to settings.txt and fill in your actual values

# === Embedding Provider Configuration (v2.3 Dual Architecture) ===
# Choose ONE embedding provider by uncommenting the appropriate section

# Option 1: Voyage AI (Recommended - 85% cost reduction vs OpenAI)
# - 512-dim vectors vs 1536-dim = 3x storage efficiency
# - Similar semantic search quality at fraction of the cost
VOYAGE_API_KEY=your_voyage_api_key_here
EMBEDDING_PROVIDER=voyage
EMBEDDING_MODEL=voyage-3-lite

# Option 2: OpenAI (comment out Voyage settings above to use this)
OPENAI_API_KEY=your_openai_api_key_here
#EMBEDDING_PROVIDER=openai
#EMBEDDING_MODEL=text-embedding-3-small

# === Chat Processing Configuration (v2.3) ===
# Required for chat history summarization features

# GPT-4.1-mini (Recommended - 78% cost reduction vs GPT-3.5-turbo)
# - Better code understanding (92% vs 85% quality score)
# - Requires OPENAI_API_KEY above
CHAT_MODEL=gpt-4.1-mini

# Legacy option (higher cost, lower quality)
#CHAT_MODEL=gpt-3.5-turbo

# === Qdrant Vector Database Configuration ===
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your_qdrant_api_key_here

# === Legacy Settings (for backward compatibility) ===
openai_api_key=your_openai_api_key_here
qdrant_url=http://localhost:6333
qdrant_api_key=your_qdrant_api_key_here

# Indexer Settings
indexer_debug=false
indexer_verbose=true
debounce_seconds=60

# File Processing Settings
include_markdown=true
include_tests=false
max_file_size=1048576

# Service Configuration
service_config_path=~/.claude-indexer/config.json
auto_start_service=false